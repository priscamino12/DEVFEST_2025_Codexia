# apps/audio/inference.py
import os
import requests
import json

ML_API_URL = os.getenv("AUDIO_ML_API_URL", "http://34.63.213.198:8080/predict")

def analyze_audio(file_path: str) -> dict:
    print(f"üì° [Inference] Envoi vers {ML_API_URL}...")
    
    try:
        with open(file_path, 'rb') as f:
            # MODIFICATION ICI : On passe √† 120 secondes (2 minutes)
            response = requests.post(ML_API_URL, files={'audio': f}, timeout=120)

        response.raise_for_status()
        data = response.json()
        
        print(f"‚úÖ R√©ponse brute API : {data}")

        # --- MAPPING EXACT (Conserv√© de l'√©tape pr√©c√©dente) ---
        
        # 1. Score
        confidence = float(data.get("deepfake_prob", 0.0))

        # 2. Verdict
        prediction_label = data.get("prediction", "bonafide")
        is_deepfake = (prediction_label == "deepfake")

        # 3. M√©tadonn√©es
        transcription = "Transcription non fournie par le mod√®le"
        duration = 0.0 

        result = {
            "status": "success",
            "transcription": transcription,
            "confidence_score": round(confidence, 4),
            "duration_seconds": duration,
            "is_deepfake": is_deepfake
        }
        
        print(f"üöÄ R√©sultat format√© pour DB : {result}")
        return result

    except requests.exceptions.Timeout:
        # On capture sp√©cifiquement l'erreur de timeout pour l'afficher clairement
        print("‚ùå ERREUR : Le serveur IA est trop lent (Timeout > 120s)")
        raise Exception("Le serveur IA met trop de temps √† r√©pondre. Essayez un fichier plus court.")

    except Exception as e:
        print(f"‚ùå Erreur API ML : {e}")
        raise e
